# Transformer-pytorch
A PyTorch implementation of Transformer in "Attention is All You Need" (https://arxiv.org/abs/1706.03762)

**Taken from: https://github.com/graykode/nlp-tutorial**

This repo focuses on a simple implementation of the paper.

## Requirements
- Python 3.7+
- Latest version of pytorch (https://pytorch.org/: v 1.2.0)
(Check it from terminal in linux:"python -c "import torch; print(torch._ _version_ _)"

**Versions above this will cause errors.**

- [NumPy](http://www.numpy.org/)
- [NLTK](https://www.nltk.org/)
- [tqdm](https://github.com/tqdm/tqdm)

## Usage
### Train + Test model
(Have in mind that in trains and "tests" with the same phrase)

It will depict the attention plot of the given sentence.
```
$ python simple_transformer.py
```
## Reference

**- Repository cloned from: [@graykode/nlp-tutorial](https://github.com/graykode/nlp-tutorial)**
## Author
**[@graykode](https://github.com/graykode)**
**Tae Hwan Jung(Jeff Jung), Email : nlkey2022@gmail.com**
